{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 1: [9.206 5.806 9.795 7.452], 0.014636\n",
      "Sample 2: [9.123 5.265 8.88  5.74 ], 0.011781\n",
      "Sample 3: [0.661 2.222 3.34  7.025], 2.3e-05\n",
      "Sample 4: [2.022 2.641 2.202 2.139], 3.2e-05\n",
      "Sample 5: [0.501 2.135 3.23  1.475], 8.6e-05\n",
      "Sample 6: [0.363 1.749 2.184 1.032], 1.7e-05\n",
      "Sample 7: [5.306 5.682 0.108 5.365], 0.001569\n",
      "Sample 8: [0.608 8.135 1.662 2.234], 0.004223\n",
      "Sample 9: [5.049 3.675 4.728 4.297], 0.000879\n",
      "Sample 10: [7.569 8.265 5.136 5.122], 0.006847\n",
      "Sample 11: [0.16  6.248 5.637 4.814], 0.001882\n",
      "Sample 12: [3.649 6.6   2.837 8.771], 0.001704\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nsamples_per_method = 4\\n\\ndef in_list(arr, lst):\\n    if lst == []:\\n        return False\\n    for item in lst:\\n        if np.allclose(arr, item, atol=1e-3):\\n            return True\\n    return False\\n\\ndef bayesian_optimize(func, bounds, args=None):\\n    global_mins = []\\n    iterations = 15\\n    X_copy = [val for val in X]\\n    y_copy = [val for val in y]\\n    for i in range(iterations):\\n        np.random.seed(i)\\n        model.fit(X_copy, y_copy)\\n        guess = guess_in_bounds(bounds)\\n        global_min = minimize(func, guess, bounds=bounds, method='Nelder-Mead', args=(model, args))\\n        x_guess = global_min.x.round(3)\\n        y_guess = model.predict(x_guess.reshape(1, -1)).round(6)\\n        if in_list(x_guess, X_copy) == False:\\n            X_copy.append(x_guess)\\n            y_copy.append(float(y_guess))\\n            global_mins.append((x_guess, y_guess))\\n    return sorted(global_mins, key=lambda x: x[1], reverse=True)\\n\\ndef non_bayesian_optimize(func, bounds, args=None, model_used=False):\\n    global_mins = []\\n    X_copy = [val for val in X]\\n    iterations = 15\\n    for i in range(iterations):\\n        np.random.seed(i)\\n        guess = guess_in_bounds(bounds)\\n        if model_used==False:\\n            global_min = minimize(func, guess, bounds=bounds, method='Nelder-Mead', args=(args))\\n        else:\\n            model.fit(X, y)\\n            global_min = minimize(func, guess, bounds=bounds, method='Nelder-Mead', args=(model))\\n        x_guess = global_min.x.round(3)\\n        y_guess = global_min.fun.round(6)\\n        if in_list(x_guess, X_copy) == False:\\n            X_copy.append(x_guess)\\n            global_mins.append((x_guess, -y_guess))\\n    return sorted(global_mins, key=lambda x: x[1], reverse=True)\\n\\ndef ML_func(guess, model):\\n    return -model.predict(guess.reshape(1, -1))\\n\\nlcb_exploration_weight = 1.0\\nucb_exploration_weight = 1.0\\n\\nmins_to_test = {\\n    'Conductivity Function': non_bayesian_optimize(conductivity_func, bounds, args=(True)),\\n    'Non-Bayesian Optimization': non_bayesian_optimize(ML_func, bounds, model_used=True),\\n    'Custom Function': bayesian_optimize(acquisition_function1, bounds, args=(lcb_exploration_weight)),\\n    'Upper Confidence Bound': bayesian_optimize(acquisition_function2, bounds, args=(ucb_exploration_weight)),\\n    'Probability of Improvement': bayesian_optimize(acquisition_function3, bounds, args=(max(y)))\\n}\\n\\nfor key in mins_to_test.keys():\\n    print(f'{key}:')\\n    for index in range(samples_per_method):\\n        print(mins_to_test[key][index][0].round(3), mins_to_test[key][index][1].round(6), conductivity_func(mins_to_test[key][index][0].round(6)))\\n\\n\""
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "from xgboost import XGBRegressor\n",
    "from scipy.optimize import minimize, rosen\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "from sklearn.gaussian_process.kernels import ConstantKernel as C, WhiteKernel as W, RBF, Matern, RationalQuadratic as RQ, ExpSineSquared as ESS, DotProduct as DP, Sum, Product\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "#===========================================================================================================#\n",
    "#Obtaining initial values\n",
    "\n",
    "def conductivity_func(X, finding_min=False):\n",
    "    if finding_min==False:\n",
    "        return (rosen(X.T) * 1e-8).round(6)\n",
    "    elif finding_min==True:\n",
    "        return -(rosen(X.T) * 1e-8).round(6)\n",
    "\n",
    "np.random.seed(10003)\n",
    "samples = 12\n",
    "concentrations = 4\n",
    "X = (np.random.random((samples, concentrations))*10).round(3)\n",
    "y = conductivity_func(X).round(6)\n",
    "\n",
    "for i in range(len(y)):\n",
    "    print(f'Sample {i+1}: {X[i]}, {y[i]}')\n",
    "\n",
    "#===========================================================================================================#\n",
    "#Declaring Machine Learning Model Used\n",
    "'''\n",
    "kernel = 31.6**2 * RBF(length_scale=10, length_scale_bounds=(10.0, 10000.0)) + DP(sigma_0=1e+04, sigma_0_bounds=(0.001, 10000.0))\n",
    "model = GaussianProcessRegressor(kernel = kernel, normalize_y=True, alpha=1e-8)\n",
    "'''\n",
    "#===========================================================================================================#\n",
    "#Bayesian Optimization\n",
    "'''\n",
    "def guess_in_bounds(bounds):\n",
    "    return [(b[1] - b[0]) * np.random.random() + b[0] for b in bounds]\n",
    "\n",
    "def acquisition_function1(x, model, explore_weight=1.0):\n",
    "    pred, std = model.predict([x], return_std=True)\n",
    "    return -(pred - std * explore_weight)\n",
    "\n",
    "def acquisition_function2(x, model, explore_weight=1.0):\n",
    "    pred, std = model.predict([x], return_std=True)\n",
    "    return -(pred + std * explore_weight)\n",
    "\n",
    "def acquisition_function3(x, model, best_y):\n",
    "    pred, std = model.predict([x], return_std=True)\n",
    "    return -(norm.cdf((pred - best_y)/std))\n",
    "\n",
    "bounds = [(0, 10)] * concentrations\n",
    "'''\n",
    "#===========================================================================================================#\n",
    "#Global Minimum\n",
    "'''\n",
    "samples_per_method = 4\n",
    "\n",
    "def in_list(arr, lst):\n",
    "    if lst == []:\n",
    "        return False\n",
    "    for item in lst:\n",
    "        if np.allclose(arr, item, atol=1e-3):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def bayesian_optimize(func, bounds, args=None):\n",
    "    global_mins = []\n",
    "    iterations = 15\n",
    "    X_copy = [val for val in X]\n",
    "    y_copy = [val for val in y]\n",
    "    for i in range(iterations):\n",
    "        np.random.seed(i)\n",
    "        model.fit(X_copy, y_copy)\n",
    "        guess = guess_in_bounds(bounds)\n",
    "        global_min = minimize(func, guess, bounds=bounds, method='Nelder-Mead', args=(model, args))\n",
    "        x_guess = global_min.x.round(3)\n",
    "        y_guess = model.predict(x_guess.reshape(1, -1)).round(6)\n",
    "        if in_list(x_guess, X_copy) == False:\n",
    "            X_copy.append(x_guess)\n",
    "            y_copy.append(float(y_guess))\n",
    "            global_mins.append((x_guess, y_guess))\n",
    "    return sorted(global_mins, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "def non_bayesian_optimize(func, bounds, args=None, model_used=False):\n",
    "    global_mins = []\n",
    "    X_copy = [val for val in X]\n",
    "    iterations = 15\n",
    "    for i in range(iterations):\n",
    "        np.random.seed(i)\n",
    "        guess = guess_in_bounds(bounds)\n",
    "        if model_used==False:\n",
    "            global_min = minimize(func, guess, bounds=bounds, method='Nelder-Mead', args=(args))\n",
    "        else:\n",
    "            model.fit(X, y)\n",
    "            global_min = minimize(func, guess, bounds=bounds, method='Nelder-Mead', args=(model))\n",
    "        x_guess = global_min.x.round(3)\n",
    "        y_guess = global_min.fun.round(6)\n",
    "        if in_list(x_guess, X_copy) == False:\n",
    "            X_copy.append(x_guess)\n",
    "            global_mins.append((x_guess, -y_guess))\n",
    "    return sorted(global_mins, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "def ML_func(guess, model):\n",
    "    return -model.predict(guess.reshape(1, -1))\n",
    "\n",
    "lcb_exploration_weight = 1.0\n",
    "ucb_exploration_weight = 1.0\n",
    "\n",
    "mins_to_test = {\n",
    "    'Conductivity Function': non_bayesian_optimize(conductivity_func, bounds, args=(True)),\n",
    "    'Non-Bayesian Optimization': non_bayesian_optimize(ML_func, bounds, model_used=True),\n",
    "    'Custom Function': bayesian_optimize(acquisition_function1, bounds, args=(lcb_exploration_weight)),\n",
    "    'Upper Confidence Bound': bayesian_optimize(acquisition_function2, bounds, args=(ucb_exploration_weight)),\n",
    "    'Probability of Improvement': bayesian_optimize(acquisition_function3, bounds, args=(max(y)))\n",
    "}\n",
    "\n",
    "for key in mins_to_test.keys():\n",
    "    print(f'{key}:')\n",
    "    for index in range(samples_per_method):\n",
    "        print(mins_to_test[key][index][0].round(3), mins_to_test[key][index][1].round(6), conductivity_func(mins_to_test[key][index][0].round(6)))\n",
    "\n",
    "'''\n",
    "#===========================================================================================================#\n",
    "#Testing XGB Regressor\n",
    "model = XGBRegressor()\n",
    "param_grid = [\n",
    "    {'n_estimators': [Product(C(31.6**2), Sum(RBF(length_scale=10), DP(sigma_0=1e+04)))],\n",
    "     'learning_rate': kern1_bounds,\n",
    "     'max_depth': kern2_bounds,\n",
    "     'num_boost_round': kern3_bounds}\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "kernel = 31.6**2 * RBF(length_scale=10, length_scale_bounds=(10.0, 10000.0)) + DP(sigma_0=1e+04, sigma_0_bounds=(0.001, 10000.0))\n",
    "\n",
    "model = GaussianProcessRegressor(kernel = kernel, normalize_y=True, alpha=1e-8)\n",
    "\n",
    "score = -5.251450383038068e-06\n",
    "\n",
    "error: -0.0012242895406499746"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conductivity Function:\n",
    "[10. 10. 10.  0.] 0.026202\n",
    "[1.e+01 1.e+01 1.e+01 8.e-03] 0.026201\n",
    "[10.  0. 10.  0.] 0.020102\n",
    "[ 0.058 10.    10.     0.   ] 0.018202\n",
    "\n",
    "1.0\n",
    "Lower Confidence Bound:\n",
    "[10. 10. 10. 10.] [0.021217] 0.024302\n",
    "[10. 10. 10.  0.] [0.019906] 0.026202\n",
    "[10.  0. 10. 10.] [0.014653] 0.018202\n",
    "[ 0.565 10.     0.352  0.   ] [0.007338] 0.010024\n",
    "Upper Confidence Bound:\n",
    "[10. 10. 10. 10.] [0.021217] 0.024302\n",
    "[10. 10. 10.  0.] [0.019906] 0.026202\n",
    "[10.  0. 10. 10.] [0.014653] 0.018202\n",
    "[10.  0. 10.  0.] [0.011726] 0.020102\n",
    "\n",
    "2.0\n",
    "Lower Confidence Bound:\n",
    "[10.    10.    10.     9.508] [0.021007] 0.024391\n",
    "[10.     9.163 10.    10.   ] [0.020461] 0.021823\n",
    "[10.     9.092 10.     9.513] [0.020177] 0.021735\n",
    "[10. 10. 10.  0.] [0.019906] 0.026202\n",
    "Upper Confidence Bound:\n",
    "[10. 10. 10.  0.] [0.019906] 0.026202\n",
    "[10.  0. 10. 10.] [0.014653] 0.018202\n",
    "[10.  0. 10.  0.] [0.011726] 0.020102\n",
    "[10. 10.  0.  0.] [0.01108] 0.018102\n",
    "\n",
    "5.0\n",
    "Lower Confidence Bound:\n",
    "[10.     6.555 10.     7.718] [0.017212] 0.018337\n",
    "[ 9.728  6.348 10.     7.77 ] [0.016555] 0.017222\n",
    "[0.608 8.136 1.661 2.233] [0.004225] 0.004226\n",
    "[0.16  6.249 5.637 4.814] [0.001883] 0.001883\n",
    "Upper Confidence Bound:\n",
    "[10. 10. 10.  0.] [0.019906] 0.026202\n",
    "[10.  0. 10. 10.] [0.014653] 0.018202\n",
    "[10.  0. 10.  0.] [0.011726] 0.020102\n",
    "[10. 10.  0.  0.] [0.01108] 0.018102\n",
    "\n",
    "10.0\n",
    "Lower Confidence Bound:\n",
    "[10.     6.112 10.     7.196] [0.016645] 0.018178\n",
    "[ 9.308  5.938 10.     7.713] [0.015432] 0.015671\n",
    "[7.578 8.27  5.145 5.122] [0.006871] 0.006872\n",
    "[0.16  6.249 5.637 4.814] [0.001882] 0.001882\n",
    "Upper Confidence Bound:\n",
    "[10. 10. 10.  0.] [0.019906] 0.026202\n",
    "[10.  0. 10. 10.] [0.014653] 0.018202\n",
    "[10.  0. 10.  0.] [0.011726] 0.020102\n",
    "[10. 10.  0.  0.] [0.01108] 0.018102"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9.206, 5.806, 9.795, 7.452], [9.123, 5.265, 8.88, 5.74], [0.661, 2.222, 3.34, 7.025], [2.022, 2.641, 2.202, 2.139], [0.501, 2.135, 3.23, 1.475], [0.363, 1.749, 2.184, 1.032], [5.306, 5.682, 0.108, 5.365], [0.608, 8.135, 1.662, 2.234], [5.049, 3.675, 4.728, 4.297], [7.569, 8.265, 5.136, 5.122], [0.16, 6.248, 5.637, 4.814], [3.649, 6.6, 2.837, 8.771], '4']\n",
      "[[9.206, 5.806, 9.795, 7.452], [9.123, 5.265, 8.88, 5.74], [0.661, 2.222, 3.34, 7.025], [2.022, 2.641, 2.202, 2.139], [0.501, 2.135, 3.23, 1.475], [0.363, 1.749, 2.184, 1.032], [5.306, 5.682, 0.108, 5.365], [0.608, 8.135, 1.662, 2.234], [5.049, 3.675, 4.728, 4.297], [7.569, 8.265, 5.136, 5.122], [0.16, 6.248, 5.637, 4.814], [3.649, 6.6, 2.837, 8.771]]\n",
      "[[9.206, 5.806, 9.795, 7.452], [9.123, 5.265, 8.88, 5.74], [0.661, 2.222, 3.34, 7.025], [2.022, 2.641, 2.202, 2.139], [0.501, 2.135, 3.23, 1.475], [0.363, 1.749, 2.184, 1.032], [5.306, 5.682, 0.108, 5.365], [0.608, 8.135, 1.662, 2.234], [5.049, 3.675, 4.728, 4.297], [7.569, 8.265, 5.136, 5.122], [0.16, 6.248, 5.637, 4.814], [3.649, 6.6, 2.837, 8.771], '4']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'ree'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = [[9.206, 5.806, 9.795, 7.452],\n",
    " [9.123, 5.265, 8.88,  5.74 ],\n",
    " [0.661, 2.222, 3.34,  7.025],\n",
    " [2.022, 2.641, 2.202, 2.139],\n",
    " [0.501, 2.135, 3.23,  1.475],\n",
    " [0.363, 1.749, 2.184, 1.032],\n",
    " [5.306, 5.682, 0.108, 5.365],\n",
    " [0.608, 8.135, 1.662, 2.234],\n",
    " [5.049, 3.675, 4.728, 4.297],\n",
    " [7.569, 8.265, 5.136, 5.122],\n",
    " [0.16,  6.248, 5.637, 4.814],\n",
    " [3.649, 6.6,   2.837, 8.771]]\n",
    "\n",
    "y = [1.4636e-02, 1.1781e-02, 2.3000e-05, 3.2000e-05, 8.6000e-05, 1.7000e-05,\n",
    "1.5690e-03, 4.2230e-03, 8.7900e-04, 6.8470e-03, 1.8820e-03, 1.7040e-03]\n",
    "\n",
    "\n",
    "def function(X=X, y=y):\n",
    "    X_orig = [x for x in X]\n",
    "    X_orig.append('4')\n",
    "    #print(X)\n",
    "    #print(y)\n",
    "    print(X_orig)\n",
    "    X = X_orig\n",
    "    return 'ree'\n",
    "\n",
    "function(X, y)\n",
    "print(X)\n",
    "#print(y)\n",
    "\n",
    "function(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 1: [9.206 5.806 9.795 7.452], 0.014636\n",
      "Sample 2: [9.123 5.265 8.88  5.74 ], 0.011781\n",
      "Sample 3: [0.661 2.222 3.34  7.025], 2.3e-05\n",
      "Sample 4: [2.022 2.641 2.202 2.139], 3.2e-05\n",
      "Sample 5: [0.501 2.135 3.23  1.475], 8.6e-05\n",
      "Sample 6: [0.363 1.749 2.184 1.032], 1.7e-05\n",
      "Sample 7: [5.306 5.682 0.108 5.365], 0.001569\n",
      "Sample 8: [0.608 8.135 1.662 2.234], 0.004223\n",
      "Sample 9: [5.049 3.675 4.728 4.297], 0.000879\n",
      "Sample 10: [7.569 8.265 5.136 5.122], 0.006847\n",
      "Sample 11: [0.16  6.248 5.637 4.814], 0.001882\n",
      "Sample 12: [3.649 6.6   2.837 8.771], 0.001704\n",
      "'Conductivity Function': min_over_bounds(conductivity_func, bounds, args=(True)),\n",
      "    'Non-Baysian Optimization': min_over_bounds(ML_func, bounds, model),\n",
      "    'Lower Confidence Bound': min_over_bounds(acquisition_function1, bounds, args=(model, lcb_exploration_weight), model_used=True),\n",
      "    'Upper Confidence Bound': min_over_bounds(acquisition_function2, bounds, args=(model, ucb_exploration_weight), model_used=True),Probability of Improvement:\n",
      "[10. 10. 10.  0.] [0.019906] 0.026202\n",
      "[ 9.523  6.043 10.     7.819] [0.015954] 0.016366\n",
      "[9.285 5.835 9.917 7.53 ] [0.015071] 0.015292\n",
      "[10.  0. 10. 10.] [0.014653] 0.018202\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "from scipy.optimize import minimize, rosen\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "#from sklearn.gaussian_process.kernels import ConstantKernel, WhiteKernel, RBF, Matern, RationalQuadratic, ExpSineSquared, DotProduct, Sum, Product\n",
    "from sklearn.gaussian_process.kernels import ConstantKernel as C, WhiteKernel as W, RBF, Matern, RationalQuadratic as RQ, ExpSineSquared as ESS, DotProduct as DP, Sum, Product\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "#===========================================================================================================#\n",
    "#Obtaining initial values\n",
    "\n",
    "def conductivity_func(X, finding_min=False):\n",
    "    if finding_min==False:\n",
    "        return (rosen(X.T) * 1e-8).round(6)\n",
    "    elif finding_min==True:\n",
    "        return -(rosen(X.T) * 1e-8).round(6)\n",
    "\n",
    "np.random.seed(10003)\n",
    "samples = 12\n",
    "concentrations = 4\n",
    "X = (np.random.random((samples, concentrations))*10).round(3)\n",
    "y = conductivity_func(X).round(6)\n",
    "\n",
    "for i in range(len(y)):\n",
    "    print(f'Sample {i+1}: {X[i]}, {y[i]}')\n",
    "\n",
    "\n",
    "#===========================================================================================================#\n",
    "#Declaring ML Model Used\n",
    "\n",
    "kernel = 31.6**2 * RBF(length_scale=10, length_scale_bounds=(10.0, 10000.0)) + DP(sigma_0=1e+04, sigma_0_bounds=(0.001, 10000.0))\n",
    "model = GaussianProcessRegressor(kernel = kernel, normalize_y=True, alpha=1e-8, n_restarts_optimizer=3)\n",
    "\n",
    "#===========================================================================================================#\n",
    "#Bayesian Optimization\n",
    "\n",
    "'''def guess_in_bounds(bounds):\n",
    "    return [(b[1] - b[0]) * np.random.random() + b[0] for b in bounds]\n",
    "\n",
    "def acquisition_function1(x, model, explore_weight=1.0):\n",
    "    pred, std = model.predict([x], return_std=True)\n",
    "    return -(pred - std * explore_weight)\n",
    "\n",
    "def acquisition_function2(x, model, explore_weight=1.0):\n",
    "    pred, std = model.predict([x], return_std=True)\n",
    "    return -(pred + std * explore_weight)\n",
    "\n",
    "def acquisition_function3(x, model, best_y, explore_weight=1.0):\n",
    "    pred, std = model.predict([x], return_std=True)\n",
    "    #print(-(norm.cdf((pred - best_y)/std)))\n",
    "    return -(norm.cdf((pred - best_y)/std))\n",
    "\n",
    "bounds = [(0,10)]*concentrations'''\n",
    "\n",
    "#===========================================================================================================#\n",
    "#Global Minimum\n",
    "\n",
    "'''model.fit(X, y)\n",
    "\n",
    "def remove_duplicate(tuple_list):\n",
    "    for first_index in range(len(tuple_list)-1):\n",
    "        for second_index in list(range(first_index+1, len(tuple_list))[::-1]):\n",
    "                if (np.allclose(tuple_list[first_index][0], tuple_list[second_index][0], atol=1e-4)) and (np.isclose(tuple_list[first_index][1], tuple_list[second_index][1], atol=1e-4)):\n",
    "                        tuple_list.pop(second_index)\n",
    "    tuple_list = sorted(tuple_list, key=lambda x: x[1], reverse=True)\n",
    "    return tuple_list\n",
    "\n",
    "def min_over_bounds(func, bounds, args=None, model_used=False):\n",
    "    global_mins = []\n",
    "    iterations = 12\n",
    "    if model_used == True:\n",
    "        model = args[0]\n",
    "    for i in range(iterations):\n",
    "        np.random.seed(i)\n",
    "        guess = guess_in_bounds(bounds)\n",
    "        global_min = minimize(func, guess, bounds=bounds, method='Nelder-Mead', args=args)\n",
    "        if model_used == False:\n",
    "            global_mins.append((global_min.x, -global_min.fun))\n",
    "        else:\n",
    "            global_mins.append((global_min.x, model.predict(global_min.x.reshape(1, -1))))\n",
    "    return remove_duplicate(global_mins)\n",
    "\n",
    "def ML_func(guess, model):\n",
    "    return -model.predict(guess.reshape(1, -1))\n",
    "\n",
    "lcb_exploration_weight = 1.0\n",
    "ucb_exploration_weight = 1.0\n",
    "poi_exploration_weight= 1.0\n",
    "\n",
    "mins_to_test = {\n",
    "    'Conductivity Function': min_over_bounds(conductivity_func, bounds, args=(True)),\n",
    "    'Non-Baysian Optimization': min_over_bounds(ML_func, bounds, model),\n",
    "    'Lower Confidence Bound': min_over_bounds(acquisition_function1, bounds, args=(model, lcb_exploration_weight), model_used=True),\n",
    "    'Upper Confidence Bound': min_over_bounds(acquisition_function2, bounds, args=(model, ucb_exploration_weight), model_used=True),\n",
    "    'Probability of Improvement': min_over_bounds(acquisition_function3, bounds, args=(model, max(y), poi_exploration_weight), model_used=True)\n",
    "}\n",
    "\n",
    "for key in mins_to_test.keys():\n",
    "    print(f'{key}:')\n",
    "    for index in range(4):\n",
    "        print(mins_to_test[key][index][0].round(3), mins_to_test[key][index][1].round(6), conductivity_func(mins_to_test[key][index][0].round(6)))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = [1]\n",
    "\n",
    "if arr==None:\n",
    "    print('hi')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
